{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scape gas price data from website using Python\n",
    "\n",
    "## 1. Gasoline Tax data\n",
    "\n",
    "This notebook is for scaping data from website. Data is rarely available in the work we want it. Sometime it's hidden within the depths of the internet and need scaping from websites. \n",
    "\n",
    "I am using https://igentax.com/gas-tax-state/#table link for scraping gas tax data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries \n",
    "\n",
    "from urllib.request import Request\n",
    "from urllib.request import urlopen\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract table\n",
    "url=\"https://igentax.com/gas-tax-state/#table\"\n",
    "raw_request = Request(url)\n",
    "raw_request.add_header('User-Agent', 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:78.0) Gecko/20100101 Firefox/78.0')\n",
    "raw_request.add_header('Accept', 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8')\n",
    "resp = urlopen(raw_request)\n",
    "raw_html = resp.read()\n",
    "soup = BeautifulSoup(raw_html, 'html.parser')\n",
    "table1 = soup.find('table')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain every title of columns with tag <th>\n",
    "headers = []\n",
    "for i in table1.find_all('th'):\n",
    "    title = i.text.strip()\n",
    "    headers.append(title)\n",
    "\n",
    "mydata = pd.DataFrame(columns = headers)\n",
    "\n",
    "# Create a for loop to fill mydata\n",
    "for j in table1.find_all('tr')[1:]:\n",
    "    row_data = j.find_all('td')\n",
    "    row = [i.text.strip() for i in row_data]\n",
    "    length = len(mydata)\n",
    "    mydata.loc[length] = row\n",
    "    \n",
    "mydata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean table \n",
    "\n",
    "df = mydata[['State','Gasoline Tax']]\n",
    "df['Gasoline Tax'] = df['Gasoline Tax'].str.replace(\"$\",'')\n",
    "df['Gasoline Tax'] = df['Gasoline Tax'].str.replace(\"/ gallon\",'')\n",
    "df['Gasoline Tax'] = df['Gasoline Tax'].str.replace(\"*\",'')\n",
    "df['State'] = df['State'].str.replace(\"*\",'')\n",
    "\n",
    "\n",
    "# Replace a textual string with average of values in the string\n",
    "df.loc[df['State']=='Iowa','Gasoline Tax'] = 0.273\n",
    "df.columns = ['State','Gas_Tax']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to csv \n",
    "\n",
    "df.to_csv('data/state_gastax.csv')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Average gas price state wise in USA\n",
    "\n",
    "This data is scaped from https://www.gasbuddy.com/usa website on May 28, 2022. Gas prices keep fluctuating so if you run these line of code, you might end up with a table with different data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract table\n",
    "url=\"https://www.gasbuddy.com/usa\"\n",
    "raw_request = Request(url)\n",
    "raw_request.add_header('User-Agent', 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:78.0) Gecko/20100101 Firefox/78.0')\n",
    "raw_request.add_header('Accept', 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8')\n",
    "resp = urlopen(raw_request)\n",
    "raw_html = resp.read()\n",
    "soup = BeautifulSoup(raw_html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract state and rate data from soup data\n",
    "\n",
    "col1 = []\n",
    "col2 = []\n",
    "\n",
    "# Extract state values\n",
    "table1 = soup.find_all('div', attrs={'class':'col-sm-6 col-xs-6 siteName'})\n",
    "for row in table1:\n",
    "    col1.append(row.get_text().strip())\n",
    "\n",
    "# Extract rate data\n",
    "table2 = soup.find_all('div', attrs={'class':'col-sm-2 col-xs-3 text-right'})\n",
    "for row in table2:\n",
    "    col2.append(row.get_text().strip())\n",
    "\n",
    "# Create dataframe from list\n",
    "df_rate = pd.DataFrame(list(zip(col1,col2)),columns = ['State','Rate'])\n",
    "df_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save data to table\n",
    "df_rate.to_csv('data/state_gasrate.csv')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Population and area data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract table\n",
    "url=\"https://www.findeasy.in/top-us-states-by-population-statewise-population/\"\n",
    "raw_request = Request(url)\n",
    "raw_request.add_header('User-Agent', 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:78.0) Gecko/20100101 Firefox/78.0')\n",
    "raw_request.add_header('Accept', 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8')\n",
    "resp = urlopen(raw_request)\n",
    "raw_html = resp.read()\n",
    "soup = BeautifulSoup(raw_html, 'html.parser')\n",
    "table1 = soup.find('table')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain every title of columns this is first element with tag 'tr'\n",
    "headers = []\n",
    "for i in table1.find_all('tr')[0:1]:\n",
    "    row_data = i.find_all('td')\n",
    "    title = [i.text.strip() for i in row_data]\n",
    "    headers.append(title)\n",
    "    #title = row.text.strip()\n",
    "    #print(title,\"   \")\n",
    "    \n",
    "mydata = pd.DataFrame(columns = headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "row = []\n",
    "\n",
    "# Create a for loop to fill mydata\n",
    "for j in table1.find_all('tr')[1:]:\n",
    "    #print(j)\n",
    "    row_data = j.find_all('td')\n",
    "    #print(row_data)\n",
    "    row = [i.text.strip() for i in row_data]\n",
    "    print(row)\n",
    "    length = len(mydata)\n",
    "    mydata.loc[length] = row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean table\n",
    "\n",
    "mydata = mydata[['States', 'Population (2020)', 'Area (sq. mi)']]\n",
    "# Remove Washington DC from the data\n",
    "# Dropping last 2 rows using drop\n",
    "mydata.drop(mydata.tail(2).index,inplace = True)\n",
    "mydata.columns = ['State','Population','Area']\n",
    "mydata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata.to_csv('data/state_pop_area.csv')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. State & Local Sales Tax Rates, as of January 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract table\n",
    "url=\"https://taxfoundation.org/2021-sales-taxes/\"\n",
    "raw_request = Request(url)\n",
    "raw_request.add_header('User-Agent', 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:78.0) Gecko/20100101 Firefox/78.0')\n",
    "raw_request.add_header('Accept', 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8')\n",
    "resp = urlopen(raw_request)\n",
    "raw_html = resp.read()\n",
    "soup = BeautifulSoup(raw_html, 'html.parser')\n",
    "table1 = soup.find('table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain every title of columns with tag <th>\n",
    "headers = []\n",
    "for i in table1.find_all('th'):\n",
    "    title = i.text.strip()\n",
    "    headers.append(title)\n",
    "headers[5] = 'Rank1'\n",
    "mydata = pd.DataFrame(columns = headers)\n",
    "\n",
    "\n",
    "# Create a for loop to fill mydata\n",
    "for j in table1.find_all('tr')[1:52]:\n",
    "    row_data = j.find_all('td')\n",
    "    row = [i.text.strip() for i in row_data]\n",
    "    print(row)\n",
    "    length = len(mydata)\n",
    "    mydata.loc[length] = row\n",
    "    \n",
    "mydata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata.to_csv('data/state_salestax.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
